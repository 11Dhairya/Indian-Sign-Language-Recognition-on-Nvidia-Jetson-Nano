{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00c94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f810ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242dc9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf850ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a46f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5a86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8b4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'C:\\\\Users\\\\Welcome\\\\Downloads\\\\datata\\\\MP_Data2' \n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['accident', 'call', 'doctor', 'help', 'hot', 'lose', 'pain', 'thief'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2762b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d444a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "171d3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7d3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfacf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4040071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ab99a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175ef578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d82add97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dea0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "21/21 [==============================] - 18s 259ms/step - loss: 2.0140 - categorical_accuracy: 0.1867\n",
      "Epoch 2/2000\n",
      "21/21 [==============================] - 5s 249ms/step - loss: 1.8844 - categorical_accuracy: 0.3256\n",
      "Epoch 3/2000\n",
      "21/21 [==============================] - 5s 249ms/step - loss: 1.7293 - categorical_accuracy: 0.3194\n",
      "Epoch 4/2000\n",
      "21/21 [==============================] - 6s 265ms/step - loss: 1.6296 - categorical_accuracy: 0.3441\n",
      "Epoch 5/2000\n",
      "21/21 [==============================] - 5s 252ms/step - loss: 1.5905 - categorical_accuracy: 0.3704\n",
      "Epoch 6/2000\n",
      "21/21 [==============================] - 5s 250ms/step - loss: 1.7486 - categorical_accuracy: 0.3333\n",
      "Epoch 7/2000\n",
      "21/21 [==============================] - 5s 248ms/step - loss: 1.4065 - categorical_accuracy: 0.4167\n",
      "Epoch 8/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.3541 - categorical_accuracy: 0.4599\n",
      "Epoch 9/2000\n",
      "21/21 [==============================] - 5s 251ms/step - loss: 1.3109 - categorical_accuracy: 0.4907\n",
      "Epoch 10/2000\n",
      "21/21 [==============================] - 5s 253ms/step - loss: 1.5291 - categorical_accuracy: 0.4090\n",
      "Epoch 11/2000\n",
      "21/21 [==============================] - 5s 261ms/step - loss: 1.3551 - categorical_accuracy: 0.4414\n",
      "Epoch 12/2000\n",
      "21/21 [==============================] - 5s 257ms/step - loss: 1.6332 - categorical_accuracy: 0.4043\n",
      "Epoch 13/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 1.4639 - categorical_accuracy: 0.3796\n",
      "Epoch 14/2000\n",
      "21/21 [==============================] - 6s 292ms/step - loss: 1.3864 - categorical_accuracy: 0.4259\n",
      "Epoch 15/2000\n",
      "21/21 [==============================] - 5s 248ms/step - loss: 1.3793 - categorical_accuracy: 0.4429\n",
      "Epoch 16/2000\n",
      "21/21 [==============================] - 5s 251ms/step - loss: 1.3050 - categorical_accuracy: 0.4877\n",
      "Epoch 17/2000\n",
      "21/21 [==============================] - 6s 263ms/step - loss: 1.3304 - categorical_accuracy: 0.4753\n",
      "Epoch 18/2000\n",
      "21/21 [==============================] - 5s 249ms/step - loss: 3.0944 - categorical_accuracy: 0.4491\n",
      "Epoch 19/2000\n",
      "21/21 [==============================] - 5s 249ms/step - loss: 1.6132 - categorical_accuracy: 0.3812\n",
      "Epoch 20/2000\n",
      "21/21 [==============================] - 5s 253ms/step - loss: 1.4322 - categorical_accuracy: 0.4228\n",
      "Epoch 21/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.3653 - categorical_accuracy: 0.4120\n",
      "Epoch 22/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.2869 - categorical_accuracy: 0.4753\n",
      "Epoch 23/2000\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 1.2364 - categorical_accuracy: 0.4907\n",
      "Epoch 24/2000\n",
      "21/21 [==============================] - 6s 267ms/step - loss: 1.2196 - categorical_accuracy: 0.4753\n",
      "Epoch 25/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.1839 - categorical_accuracy: 0.5077\n",
      "Epoch 26/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.1372 - categorical_accuracy: 0.5108\n",
      "Epoch 27/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.0744 - categorical_accuracy: 0.5509\n",
      "Epoch 28/2000\n",
      "21/21 [==============================] - 6s 262ms/step - loss: 1.0745 - categorical_accuracy: 0.5509\n",
      "Epoch 29/2000\n",
      "21/21 [==============================] - 5s 257ms/step - loss: 1.2181 - categorical_accuracy: 0.5015\n",
      "Epoch 30/2000\n",
      "21/21 [==============================] - 6s 265ms/step - loss: 1.1146 - categorical_accuracy: 0.5370\n",
      "Epoch 31/2000\n",
      "21/21 [==============================] - 6s 265ms/step - loss: 1.1432 - categorical_accuracy: 0.5062\n",
      "Epoch 32/2000\n",
      "21/21 [==============================] - 5s 257ms/step - loss: 1.0880 - categorical_accuracy: 0.5216\n",
      "Epoch 33/2000\n",
      "21/21 [==============================] - 5s 255ms/step - loss: 1.0510 - categorical_accuracy: 0.5602\n",
      "Epoch 34/2000\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 1.1191 - categorical_accuracy: 0.5463\n",
      "Epoch 35/2000\n",
      "21/21 [==============================] - 6s 260ms/step - loss: 1.3006 - categorical_accuracy: 0.5278\n",
      "Epoch 36/2000\n",
      "21/21 [==============================] - 6s 262ms/step - loss: 1.1729 - categorical_accuracy: 0.5231\n",
      "Epoch 37/2000\n",
      "21/21 [==============================] - 5s 256ms/step - loss: 1.2690 - categorical_accuracy: 0.5015\n",
      "Epoch 38/2000\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 1.2183 - categorical_accuracy: 0.4846\n",
      "Epoch 39/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.1294 - categorical_accuracy: 0.5355\n",
      "Epoch 40/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.0850 - categorical_accuracy: 0.5355\n",
      "Epoch 41/2000\n",
      "21/21 [==============================] - 6s 261ms/step - loss: 1.0517 - categorical_accuracy: 0.5710\n",
      "Epoch 42/2000\n",
      "21/21 [==============================] - 6s 273ms/step - loss: 1.0375 - categorical_accuracy: 0.5556\n",
      "Epoch 43/2000\n",
      "21/21 [==============================] - 5s 256ms/step - loss: 1.2048 - categorical_accuracy: 0.5093\n",
      "Epoch 44/2000\n",
      "21/21 [==============================] - 6s 261ms/step - loss: 1.1083 - categorical_accuracy: 0.5386\n",
      "Epoch 45/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.0298 - categorical_accuracy: 0.5802\n",
      "Epoch 46/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.0495 - categorical_accuracy: 0.5802\n",
      "Epoch 47/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.3695 - categorical_accuracy: 0.4907\n",
      "Epoch 48/2000\n",
      "21/21 [==============================] - 6s 269ms/step - loss: 1.3117 - categorical_accuracy: 0.4938\n",
      "Epoch 49/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.3459 - categorical_accuracy: 0.4460\n",
      "Epoch 50/2000\n",
      "21/21 [==============================] - 5s 259ms/step - loss: 1.2438 - categorical_accuracy: 0.4892\n",
      "Epoch 51/2000\n",
      "21/21 [==============================] - 6s 264ms/step - loss: 1.1761 - categorical_accuracy: 0.4892\n",
      "Epoch 52/2000\n",
      "21/21 [==============================] - 6s 269ms/step - loss: 1.1100 - categorical_accuracy: 0.5432\n",
      "Epoch 53/2000\n",
      "21/21 [==============================] - 5s 256ms/step - loss: 1.0973 - categorical_accuracy: 0.5509\n",
      "Epoch 54/2000\n",
      "21/21 [==============================] - 9s 435ms/step - loss: 1.0691 - categorical_accuracy: 0.5448\n",
      "Epoch 55/2000\n",
      "21/21 [==============================] - 9s 414ms/step - loss: 1.0555 - categorical_accuracy: 0.5633\n",
      "Epoch 56/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 3.4892 - categorical_accuracy: 0.5077\n",
      "Epoch 57/2000\n",
      "21/21 [==============================] - 5s 255ms/step - loss: 17.1486 - categorical_accuracy: 0.2531\n",
      "Epoch 58/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 46.9939 - categorical_accuracy: 0.1975\n",
      "Epoch 59/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 6.5621 - categorical_accuracy: 0.1944\n",
      "Epoch 60/2000\n",
      "21/21 [==============================] - 5s 253ms/step - loss: 3.9421 - categorical_accuracy: 0.2361\n",
      "Epoch 61/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 1.7256 - categorical_accuracy: 0.2793\n",
      "Epoch 62/2000\n",
      "21/21 [==============================] - 5s 255ms/step - loss: 1.6811 - categorical_accuracy: 0.2778\n",
      "Epoch 63/2000\n",
      "21/21 [==============================] - 5s 256ms/step - loss: 1.6570 - categorical_accuracy: 0.2855\n",
      "Epoch 64/2000\n",
      "21/21 [==============================] - 5s 255ms/step - loss: 1.6145 - categorical_accuracy: 0.3040\n",
      "Epoch 65/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 1.6184 - categorical_accuracy: 0.3133\n",
      "Epoch 66/2000\n",
      "21/21 [==============================] - 10s 486ms/step - loss: 1.5735 - categorical_accuracy: 0.3441\n",
      "Epoch 67/2000\n",
      "21/21 [==============================] - 7s 323ms/step - loss: 1.6114 - categorical_accuracy: 0.3796\n",
      "Epoch 68/2000\n",
      "21/21 [==============================] - 5s 256ms/step - loss: 1.5445 - categorical_accuracy: 0.3904\n",
      "Epoch 69/2000\n",
      "21/21 [==============================] - 5s 257ms/step - loss: 1.5950 - categorical_accuracy: 0.3873\n",
      "Epoch 70/2000\n",
      "21/21 [==============================] - 5s 254ms/step - loss: 1.5344 - categorical_accuracy: 0.4151\n",
      "Epoch 71/2000\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 1.5176 - categorical_accuracy: 0.4090\n",
      "Epoch 72/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 5s 254ms/step - loss: 1.4968 - categorical_accuracy: 0.4475\n",
      "Epoch 73/2000\n",
      "21/21 [==============================] - 5s 253ms/step - loss: 1.5285 - categorical_accuracy: 0.4074\n",
      "Epoch 74/2000\n",
      "21/21 [==============================] - 5s 252ms/step - loss: 1.4850 - categorical_accuracy: 0.4460\n",
      "Epoch 75/2000\n",
      "21/21 [==============================] - 5s 251ms/step - loss: 1.4597 - categorical_accuracy: 0.4383\n",
      "Epoch 76/2000\n",
      "21/21 [==============================] - 10s 467ms/step - loss: 1.5260 - categorical_accuracy: 0.4059\n",
      "Epoch 77/2000\n",
      "21/21 [==============================] - 10s 440ms/step - loss: 1.4574 - categorical_accuracy: 0.4383\n",
      "Epoch 78/2000\n",
      "21/21 [==============================] - 8s 357ms/step - loss: 1.4386 - categorical_accuracy: 0.4352\n",
      "Epoch 79/2000\n",
      "21/21 [==============================] - 7s 308ms/step - loss: 1.4518 - categorical_accuracy: 0.4198\n",
      "Epoch 80/2000\n",
      "21/21 [==============================] - 6s 280ms/step - loss: 1.4758 - categorical_accuracy: 0.4198\n",
      "Epoch 81/2000\n",
      "21/21 [==============================] - 9s 453ms/step - loss: 1.4472 - categorical_accuracy: 0.4074\n",
      "Epoch 82/2000\n",
      "21/21 [==============================] - 9s 419ms/step - loss: 1.6080 - categorical_accuracy: 0.3704\n",
      "Epoch 83/2000\n",
      "21/21 [==============================] - 7s 337ms/step - loss: 1.5043 - categorical_accuracy: 0.4043\n",
      "Epoch 84/2000\n",
      "21/21 [==============================] - 5s 251ms/step - loss: 1.4614 - categorical_accuracy: 0.4444\n",
      "Epoch 85/2000\n",
      "21/21 [==============================] - 5s 250ms/step - loss: 1.4276 - categorical_accuracy: 0.4506\n",
      "Epoch 86/2000\n",
      "21/21 [==============================] - 5s 251ms/step - loss: 1.4386 - categorical_accuracy: 0.4275\n",
      "Epoch 87/2000\n",
      "21/21 [==============================] - 5s 253ms/step - loss: 1.4173 - categorical_accuracy: 0.4336\n",
      "Epoch 88/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.3897 - categorical_accuracy: 0.4583\n",
      "Epoch 89/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.3870 - categorical_accuracy: 0.4429\n",
      "Epoch 90/2000\n",
      "21/21 [==============================] - 6s 267ms/step - loss: 1.3783 - categorical_accuracy: 0.4506\n",
      "Epoch 91/2000\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 1.3744 - categorical_accuracy: 0.4645\n",
      "Epoch 92/2000\n",
      "21/21 [==============================] - 5s 260ms/step - loss: 1.3819 - categorical_accuracy: 0.4506\n",
      "Epoch 93/2000\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 1.3953 - categorical_accuracy: 0.4491\n",
      "Epoch 94/2000\n",
      "21/21 [==============================] - 6s 268ms/step - loss: 1.3391 - categorical_accuracy: 0.4645\n",
      "Epoch 95/2000\n",
      "21/21 [==============================] - 6s 269ms/step - loss: 1.3330 - categorical_accuracy: 0.4676\n",
      "Epoch 96/2000\n",
      "15/21 [====================>.........] - ETA: 1s - loss: 1.3526 - categorical_accuracy: 0.4563"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb37a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,840\n",
      "Trainable params: 596,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82fe486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 756ms/step\n",
      "(12, 8)\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2b8dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action_latest1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c0e968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6291e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e01d971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08b06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14cfd7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5eb7f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 9,  1],\n",
       "        [ 0,  2]],\n",
       "\n",
       "       [[11,  1],\n",
       "        [ 0,  0]],\n",
       "\n",
       "       [[11,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[10,  0],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[10,  1],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[ 8,  0],\n",
       "        [ 1,  3]],\n",
       "\n",
       "       [[10,  1],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[11,  0],\n",
       "        [ 0,  1]]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0e6e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef94e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74fe03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "model=tensorflow.keras.models.load_model(\"action_latest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0543a070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 1s 521ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sequence) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m30\u001b[39m:\n\u001b[0;32m     29\u001b[0m             res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mexpand_dims(sequence, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 30\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[43mactions\u001b[49m[np\u001b[38;5;241m.\u001b[39margmax(res)])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#         #3. Viz logic\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#             if res[np.argmax(res)] > threshold: \u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#                 if len(sentence) > 0: \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# Show to screen\u001b[39;00m\n\u001b[0;32m     52\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV Feed\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actions' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "#         #3. Viz logic\n",
    "#             if res[np.argmax(res)] > threshold: \n",
    "#                 if len(sentence) > 0: \n",
    "#                     if actions[np.argmax(res)] != sentence[-1]:\n",
    "#                         sentence.append(actions[np.argmax(res)])\n",
    "#                 else:\n",
    "#                     sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "#             if len(sentence) > 5: \n",
    "#                 sentence = sentence[-5:]\n",
    "\n",
    "#             # Viz probabilities\n",
    "#             image = prob_viz(res, actions, image, colors)\n",
    "\n",
    "#         cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "#         cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "#                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453c346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
